{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import optuna\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "project_path = Path.cwd().parent\n",
    "sys.path.append(project_path.as_posix())\n",
    "from pipeline.p0_data_loader import DataLoader\n",
    "from pipeline.p1_model_trainer import XGBoostTrainer\n",
    "from pipeline.p2_optuna_hpo import objective\n",
    "from pipeline.p3_model_evaluator import ModelEvaluator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8088\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"TOA Full HPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/erdemkarakoylu/data/craig_pfc_2023/step_2_cleaned/df_phy.pqt'),\n",
       " PosixPath('/Users/erdemkarakoylu/data/craig_pfc_2023/step_2_cleaned/df_rrs.pqt'),\n",
       " PosixPath('/Users/erdemkarakoylu/data/craig_pfc_2023/step_2_cleaned/df_env.pqt'),\n",
       " PosixPath('/Users/erdemkarakoylu/data/craig_pfc_2023/step_2_cleaned/df_all.pqt'),\n",
       " PosixPath('/Users/erdemkarakoylu/data/craig_pfc_2023/step_2_cleaned/df_rrs_every_every10_51total_bands.pqt')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path.home() / 'data/craig_pfc_2023/step_2_cleaned'\n",
    "assert data_path.exists()\n",
    "[i for i in data_path.glob('*.pqt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-19 12:58:11.294\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipeline.p0_data_loader\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1mData directory set to /Users/erdemkarakoylu/data/craig_pfc_2023/step_2_cleaned\u001b[0m\n",
      "\u001b[32m2025-03-19 12:58:11.295\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipeline.p0_data_loader\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m19\u001b[0m - \u001b[34m\u001b[1mRrs file used: df_rrs_every_every10_51total_bands.pqt\u001b[0m\n",
      "\u001b[32m2025-03-19 12:58:11.296\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipeline.p0_data_loader\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[34m\u001b[1mPhytoplankton file use df_phy.pqt\u001b[0m\n",
      "\u001b[32m2025-03-19 12:58:11.296\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mpipeline.p0_data_loader\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m22\u001b[0m - \u001b[34m\u001b[1mEnv file used: df_env.pqt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    data_path=data_path, rrs_file = 'df_rrs_every_every10_51total_bands.pqt', \n",
    "    phy_file='df_phy.pqt', env_file='df_env.pqt')\n",
    "dX, dX_env, dY =  loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX_env_sub = dX_env[['lat', 'temp']]\n",
    "dX = pd.concat((dX, dX_env_sub), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/erdemkarakoylu/projex/toa_2_phyto_ml/multioutput_regression')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-19 12:58:19.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m\n",
      "Train/Test split completed --> Train shape: (1009285, 53), Test shape: (252322, 53)\u001b[0m\n",
      "/Users/erdemkarakoylu/miniconda3/envs/ptoa_py312/lib/python3.12/site-packages/pandas/io/parquet.py:190: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Train/Test Split ---\n",
    "dX_train, dX_test, dY_train, dY_test = train_test_split(\n",
    "    dX, dY, test_size=0.2)\n",
    "logger.info(f'\\nTrain/Test split completed --> Train shape: {dX_train.shape}, Test shape: {dX_test.shape}')\n",
    "dX_train.to_parquet(project_path / 'models/dX_train.pqt')\n",
    "dY_train.to_parquet(project_path / 'models/dY_train.pqt')\n",
    "dX_test.to_parquet(project_path / 'models/dX_test.pqt')\n",
    "dY_test.to_parquet(project_path / 'models/dY_test.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-18 16:35:34,385] A new study created in memory with name: no-name-46b6c713-e7ba-472b-a18f-6fd674a3707b\n",
      "[I 2025-03-18 16:39:28,061] Trial 0 finished with value: 0.026452138627502064 and parameters: {'learning_rate': 0.007754500643797615, 'max_depth': 10, 'n_estimators': 412, 'subsample': 0.5774657401715373, 'colsample_bytree': 0.7471236180477316, 'gamma': 0.5327565229364415}. Best is trial 0 with value: 0.026452138627502064.\n",
      "[I 2025-03-18 16:43:43,611] Trial 1 finished with value: 0.013290540366581123 and parameters: {'learning_rate': 0.06490618570816657, 'max_depth': 8, 'n_estimators': 429, 'subsample': 0.8494034508700612, 'colsample_bytree': 0.7191864430412669, 'gamma': 0.0001353742710352044}. Best is trial 1 with value: 0.013290540366581123.\n",
      "[I 2025-03-18 16:45:59,497] Trial 2 finished with value: 0.13970760866096155 and parameters: {'learning_rate': 0.0019455326214996456, 'max_depth': 4, 'n_estimators': 303, 'subsample': 0.8844555529089925, 'colsample_bytree': 0.5727393549098636, 'gamma': 1.2775376744393632e-05}. Best is trial 1 with value: 0.013290540366581123.\n",
      "[I 2025-03-18 16:48:57,356] Trial 3 finished with value: 0.1582148494854623 and parameters: {'learning_rate': 0.0012781692185538593, 'max_depth': 7, 'n_estimators': 311, 'subsample': 0.621714688368544, 'colsample_bytree': 0.6427027021139988, 'gamma': 0.7190437771111652}. Best is trial 1 with value: 0.013290540366581123.\n",
      "[I 2025-03-18 16:51:20,957] Trial 4 finished with value: 0.016005094863884184 and parameters: {'learning_rate': 0.10204785155581171, 'max_depth': 7, 'n_estimators': 223, 'subsample': 0.9339939082767013, 'colsample_bytree': 0.5681878371556283, 'gamma': 3.2836632835384236e-05}. Best is trial 1 with value: 0.013290540366581123.\n",
      "[I 2025-03-18 16:57:41,797] Trial 5 finished with value: 0.012360770761726892 and parameters: {'learning_rate': 0.20564899183807003, 'max_depth': 10, 'n_estimators': 443, 'subsample': 0.794788283510267, 'colsample_bytree': 0.7059745039907205, 'gamma': 1.7201172461660348e-07}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:00:43,335] Trial 6 finished with value: 0.09496708512714207 and parameters: {'learning_rate': 0.004571110926451448, 'max_depth': 9, 'n_estimators': 207, 'subsample': 0.6688960073834109, 'colsample_bytree': 0.7057290891271821, 'gamma': 0.0151139862525249}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:07:39,221] Trial 7 finished with value: 0.12583450596044063 and parameters: {'learning_rate': 0.0016916889097371296, 'max_depth': 10, 'n_estimators': 370, 'subsample': 0.5771807287250155, 'colsample_bytree': 0.9624587534446825, 'gamma': 0.0001349178452409011}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:10:28,426] Trial 8 finished with value: 0.01939930627795131 and parameters: {'learning_rate': 0.18833717969040847, 'max_depth': 4, 'n_estimators': 414, 'subsample': 0.6170736321582939, 'colsample_bytree': 0.5632792258342798, 'gamma': 7.544855540200051e-05}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:13:58,159] Trial 9 finished with value: 0.015620845837967384 and parameters: {'learning_rate': 0.06320538885637283, 'max_depth': 7, 'n_estimators': 347, 'subsample': 0.7514952162349635, 'colsample_bytree': 0.7012900212373332, 'gamma': 5.602686924985747e-05}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:14:46,641] Trial 10 finished with value: 0.06821359716436119 and parameters: {'learning_rate': 0.020708786261183637, 'max_depth': 3, 'n_estimators': 95, 'subsample': 0.9996359689994918, 'colsample_bytree': 0.8674775903192921, 'gamma': 1.2284213402622088e-08}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:20:51,380] Trial 11 finished with value: 0.012836916569671132 and parameters: {'learning_rate': 0.27185822800154646, 'max_depth': 9, 'n_estimators': 482, 'subsample': 0.7981587057716079, 'colsample_bytree': 0.8311117619354791, 'gamma': 4.9830320918451006e-08}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:28:06,194] Trial 12 finished with value: 0.013079627287698353 and parameters: {'learning_rate': 0.28258666970382895, 'max_depth': 10, 'n_estimators': 499, 'subsample': 0.7673304121051923, 'colsample_bytree': 0.8420672889160493, 'gamma': 1.6215924031957633e-08}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 17:39:27,128] Trial 13 finished with value: 0.013916626862909572 and parameters: {'learning_rate': 0.027824457981416986, 'max_depth': 9, 'n_estimators': 457, 'subsample': 0.8107964708714993, 'colsample_bytree': 0.8280814414524401, 'gamma': 2.293550171587389e-07}. Best is trial 5 with value: 0.012360770761726892.\n",
      "[I 2025-03-18 18:13:52,256] Trial 14 finished with value: 0.011791784846510582 and parameters: {'learning_rate': 0.14340994429084605, 'max_depth': 9, 'n_estimators': 498, 'subsample': 0.7011139540435176, 'colsample_bytree': 0.9435938562131159, 'gamma': 8.080924179775432e-07}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 18:15:04,441] Trial 15 finished with value: 0.017535039891929394 and parameters: {'learning_rate': 0.12446771417501568, 'max_depth': 8, 'n_estimators': 74, 'subsample': 0.7056096521401425, 'colsample_bytree': 0.9874405137944481, 'gamma': 5.162382973089398e-07}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 18:32:15,841] Trial 16 finished with value: 0.025208244932982165 and parameters: {'learning_rate': 0.04457532721419962, 'max_depth': 5, 'n_estimators': 244, 'subsample': 0.5120099325996081, 'colsample_bytree': 0.904383703203858, 'gamma': 1.8102139873173844e-06}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 19:04:16,618] Trial 17 finished with value: 0.01970933942866625 and parameters: {'learning_rate': 0.12388099964666985, 'max_depth': 6, 'n_estimators': 145, 'subsample': 0.699319732598651, 'colsample_bytree': 0.6404347026584518, 'gamma': 3.6549552807799426e-06}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 19:22:01,431] Trial 18 finished with value: 0.02419926168793876 and parameters: {'learning_rate': 0.009659665961565157, 'max_depth': 8, 'n_estimators': 363, 'subsample': 0.869583892562466, 'colsample_bytree': 0.7797720064916738, 'gamma': 0.0008550251606676888}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 19:28:05,695] Trial 19 finished with value: 0.013137803443507035 and parameters: {'learning_rate': 0.04056606884462031, 'max_depth': 9, 'n_estimators': 442, 'subsample': 0.6991305423078102, 'colsample_bytree': 0.9419368501336844, 'gamma': 9.940124885710593e-08}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 20:36:24,073] Trial 20 finished with value: 0.014866241219352575 and parameters: {'learning_rate': 0.012813717132951092, 'max_depth': 10, 'n_estimators': 498, 'subsample': 0.941355002031093, 'colsample_bytree': 0.6381067804339982, 'gamma': 2.9238553995713595e-06}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 20:41:53,269] Trial 21 finished with value: 0.012940994738995876 and parameters: {'learning_rate': 0.2782369952538257, 'max_depth': 9, 'n_estimators': 462, 'subsample': 0.8129202170364831, 'colsample_bytree': 0.7844491513875912, 'gamma': 5.2514072782583063e-08}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 20:48:06,141] Trial 22 finished with value: 0.01199539129570993 and parameters: {'learning_rate': 0.17553846362720887, 'max_depth': 9, 'n_estimators': 492, 'subsample': 0.7890958335668625, 'colsample_bytree': 0.8696028941881365, 'gamma': 6.246781237900924e-07}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 20:52:36,484] Trial 23 finished with value: 0.01241155012779315 and parameters: {'learning_rate': 0.16167127581797797, 'max_depth': 8, 'n_estimators': 401, 'subsample': 0.7501643827438995, 'colsample_bytree': 0.9168068006222584, 'gamma': 6.653381271252809e-07}. Best is trial 14 with value: 0.011791784846510582.\n",
      "[I 2025-03-18 21:16:49,116] Trial 24 finished with value: 0.011635757056951884 and parameters: {'learning_rate': 0.08301458467594765, 'max_depth': 10, 'n_estimators': 466, 'subsample': 0.6577479197695524, 'colsample_bytree': 0.8935835004842283, 'gamma': 8.631996891289372e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-18 22:08:50,465] Trial 25 finished with value: 0.01645734068178877 and parameters: {'learning_rate': 0.08066406346388381, 'max_depth': 6, 'n_estimators': 383, 'subsample': 0.6620024094061914, 'colsample_bytree': 0.8981590716844158, 'gamma': 9.915721971588476e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-18 23:28:39,055] Trial 26 finished with value: 0.012982058382830284 and parameters: {'learning_rate': 0.04228108842078684, 'max_depth': 9, 'n_estimators': 474, 'subsample': 0.7218467283869471, 'colsample_bytree': 0.9922085051459899, 'gamma': 0.0010671775144386719}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-18 23:32:54,792] Trial 27 finished with value: 0.013484784129408747 and parameters: {'learning_rate': 0.08145845380976968, 'max_depth': 8, 'n_estimators': 334, 'subsample': 0.6499709449655376, 'colsample_bytree': 0.8823985625622071, 'gamma': 5.637376129421274e-07}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-18 23:39:59,379] Trial 28 finished with value: 0.011996141288240308 and parameters: {'learning_rate': 0.15512908182990395, 'max_depth': 10, 'n_estimators': 462, 'subsample': 0.5152260816747125, 'colsample_bytree': 0.939482815850613, 'gamma': 1.3967994874634081e-05}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-18 23:48:20,428] Trial 29 finished with value: 0.03494617435335536 and parameters: {'learning_rate': 0.0053115539711165735, 'max_depth': 10, 'n_estimators': 408, 'subsample': 0.6021637690261978, 'colsample_bytree': 0.7947920256375225, 'gamma': 0.0007350595918040807}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-18 23:54:26,746] Trial 30 finished with value: 0.015290741217240783 and parameters: {'learning_rate': 0.02060377890927958, 'max_depth': 9, 'n_estimators': 498, 'subsample': 0.5507331610689054, 'colsample_bytree': 0.863179793335635, 'gamma': 0.011029895660229851}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 00:02:08,110] Trial 31 finished with value: 0.012163664873667207 and parameters: {'learning_rate': 0.1659901974273114, 'max_depth': 10, 'n_estimators': 462, 'subsample': 0.5007802407809425, 'colsample_bytree': 0.935669645962771, 'gamma': 6.712879803839471e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 00:09:48,340] Trial 32 finished with value: 0.01175622453291303 and parameters: {'learning_rate': 0.11891348989438509, 'max_depth': 10, 'n_estimators': 429, 'subsample': 0.5573702779715366, 'colsample_bytree': 0.9578223642856936, 'gamma': 1.3893221613344529e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 00:16:41,920] Trial 33 finished with value: 0.012519737682976437 and parameters: {'learning_rate': 0.060589393265300946, 'max_depth': 9, 'n_estimators': 427, 'subsample': 0.5452848970065834, 'colsample_bytree': 0.9664927698268448, 'gamma': 1.2671175288095782e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 00:21:58,636] Trial 34 finished with value: 0.012765524703203102 and parameters: {'learning_rate': 0.09903787059376809, 'max_depth': 8, 'n_estimators': 393, 'subsample': 0.6374135658326303, 'colsample_bytree': 0.9980563733940592, 'gamma': 3.434490077062978e-07}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:12:31,026] Trial 35 finished with value: 0.01295429363894395 and parameters: {'learning_rate': 0.029521128419195675, 'max_depth': 10, 'n_estimators': 433, 'subsample': 0.7303784962015833, 'colsample_bytree': 0.9196286155341898, 'gamma': 2.51338942957444e-05}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:17:35,295] Trial 36 finished with value: 0.012175398988811646 and parameters: {'learning_rate': 0.1159052364724067, 'max_depth': 10, 'n_estimators': 295, 'subsample': 0.5838183971374438, 'colsample_bytree': 0.961084460766976, 'gamma': 1.2696936153494065e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:22:37,121] Trial 37 finished with value: 0.012735556720859123 and parameters: {'learning_rate': 0.2148579981802506, 'max_depth': 7, 'n_estimators': 483, 'subsample': 0.7715123881077571, 'colsample_bytree': 0.8834305637512531, 'gamma': 3.639288879321568e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:29:14,344] Trial 38 finished with value: 0.012129274581227112 and parameters: {'learning_rate': 0.07971269230545712, 'max_depth': 9, 'n_estimators': 437, 'subsample': 0.8429662053115814, 'colsample_bytree': 0.7453944762925755, 'gamma': 1.0346880268372642e-07}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:31:56,155] Trial 39 finished with value: 0.017037433856085103 and parameters: {'learning_rate': 0.05199551666705698, 'max_depth': 8, 'n_estimators': 178, 'subsample': 0.6755779170592976, 'colsample_bytree': 0.8070961503285436, 'gamma': 2.5069096156092244e-05}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:35:57,542] Trial 40 finished with value: 0.11265966620163918 and parameters: {'learning_rate': 0.002832072471414245, 'max_depth': 10, 'n_estimators': 264, 'subsample': 0.6311205665963996, 'colsample_bytree': 0.8620118731397948, 'gamma': 0.2689592796556333}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:43:21,478] Trial 41 finished with value: 0.011960454998673117 and parameters: {'learning_rate': 0.1519356402701806, 'max_depth': 10, 'n_estimators': 460, 'subsample': 0.5425733027800247, 'colsample_bytree': 0.9415862231506216, 'gamma': 1.0207539991297893e-05}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:50:27,095] Trial 42 finished with value: 0.011932553406687562 and parameters: {'learning_rate': 0.13657737133402115, 'max_depth': 10, 'n_estimators': 416, 'subsample': 0.5536804407137397, 'colsample_bytree': 0.9671778914087804, 'gamma': 7.686436397523284e-06}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 01:56:43,235] Trial 43 finished with value: 0.011799132421558766 and parameters: {'learning_rate': 0.08857312305548257, 'max_depth': 10, 'n_estimators': 428, 'subsample': 0.5464340148715382, 'colsample_bytree': 0.967508889919663, 'gamma': 0.00024343789330830135}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 02:02:29,434] Trial 44 finished with value: 0.011882554444893369 and parameters: {'learning_rate': 0.09429251000921375, 'max_depth': 10, 'n_estimators': 421, 'subsample': 0.5794382254788384, 'colsample_bytree': 0.9591385639251645, 'gamma': 0.0003890112101328092}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 02:07:32,425] Trial 45 finished with value: 0.012206766974949629 and parameters: {'learning_rate': 0.0795825736947406, 'max_depth': 10, 'n_estimators': 322, 'subsample': 0.5930160353700091, 'colsample_bytree': 0.9654591690276758, 'gamma': 0.00030518291193520956}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 02:28:18,489] Trial 46 finished with value: 0.014034137469416017 and parameters: {'learning_rate': 0.03403234827807054, 'max_depth': 9, 'n_estimators': 376, 'subsample': 0.5691441317571209, 'colsample_bytree': 0.9221126814736023, 'gamma': 0.0003013659671778601}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 03:13:23,177] Trial 47 finished with value: 0.013146576533371014 and parameters: {'learning_rate': 0.10379681463870033, 'max_depth': 10, 'n_estimators': 360, 'subsample': 0.6815272157064529, 'colsample_bytree': 0.98114766092114, 'gamma': 0.0029465765308714924}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 03:59:45,485] Trial 48 finished with value: 0.012755830785589688 and parameters: {'learning_rate': 0.23441326409216212, 'max_depth': 9, 'n_estimators': 421, 'subsample': 0.6109171898305559, 'colsample_bytree': 0.899744604793625, 'gamma': 5.331183705062504e-05}. Best is trial 24 with value: 0.011635757056951884.\n",
      "[I 2025-03-19 04:03:08,167] Trial 49 finished with value: 0.02412738266000144 and parameters: {'learning_rate': 0.058537167875673125, 'max_depth': 4, 'n_estimators': 447, 'subsample': 0.5319167791650249, 'colsample_bytree': 0.9522561100910928, 'gamma': 0.00018681029270814376}. Best is trial 24 with value: 0.011635757056951884.\n",
      "\u001b[32m2025-03-19 04:03:08.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1m===  Basic Pipeline and Quick HPO Test Completed ===\u001b[0m\n",
      "\u001b[32m2025-03-19 04:03:08.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m---50 trials took 41253.93 seconds.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters from quick HPO test: {'learning_rate': 0.08301458467594765, 'max_depth': 10, 'n_estimators': 466, 'subsample': 0.6577479197695524, 'colsample_bytree': 0.8935835004842283, 'gamma': 8.631996891289372e-06}\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3 Run Full HPO with MedianPruner and 5 warmup steps.\n",
    "N_TRIALS= 50\n",
    "start_time = time.time()\n",
    "with mlflow.start_run():\n",
    "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)  # Stop trials that fall below the median after 5 steps\n",
    "    study = optuna.create_study(study_name=\"full_pipeline_training\", direction=\"minimize\", pruner=pruner)\n",
    "    study.optimize(lambda trial: objective(trial, dX_train, dY_train), n_trials=N_TRIALS)\n",
    "    best_params = study.best_trial.params\n",
    "    print(\"Best hyperparameters from quick HPO test:\", best_params)\n",
    "elapsed_time = time.time() - start_time\n",
    "logger.info(\"===  HPO Completed ===\")\n",
    "logger.info(f'---{N_TRIALS} trials took {elapsed_time:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retraining optimized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.08301458467594765, 'max_depth': 10, 'n_estimators': 466, 'subsample': 0.6577479197695524, 'colsample_bytree': 0.8935835004842283, 'gamma': 8.631996891289372e-06}\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model_trainer = XGBoostTrainer(params=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_model = optimized_model_trainer.train_model(dX_train, dY_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-19 11:22:29.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mModel saved to models/optimzied_model.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the final model to a file\n",
    "joblib.dump(optimized_model, project_path / \"models/optimized_model.pkl\")\n",
    "logger.info(\"Model saved to models/optimzied_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the optimzied mode\n",
    "# Later, you can load it with:\n",
    "#optimized_model = joblib.load(\"fmodels/optimized_model.pkl\")\n",
    "#logger.info(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dY_pred = optimized_model.predict(dX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dY_pred = pd.DataFrame(\n",
    "    dY_pred, columns=dY_test.columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 252322 entries, 1956024 to 1633618\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   dia        252322 non-null  float64\n",
      " 1   chl        252322 non-null  float64\n",
      " 2   cya        252322 non-null  float64\n",
      " 3   coc        252322 non-null  float64\n",
      " 4   din        252322 non-null  float64\n",
      " 5   pha        252322 non-null  float64\n",
      " 6   tot_cphyl  252322 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 15.4 MB\n"
     ]
    }
   ],
   "source": [
    "dY_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252322 entries, 0 to 252321\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   dia        252322 non-null  float32\n",
      " 1   chl        252322 non-null  float32\n",
      " 2   cya        252322 non-null  float32\n",
      " 3   coc        252322 non-null  float32\n",
      " 4   din        252322 non-null  float32\n",
      " 5   pha        252322 non-null  float32\n",
      " 6   tot_cphyl  252322 non-null  float32\n",
      "dtypes: float32(7)\n",
      "memory usage: 6.7 MB\n"
     ]
    }
   ],
   "source": [
    "dY_pred.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Short Guide to XGBOOST Hyperparameter Explanation and Interpretation\n",
    "\n",
    "1. **learning_rate**  \n",
    "   - **What it does:** Controls the step size at each boosting iteration. A smaller value means the model learns more slowly but can yield a more robust model if combined with a larger number of estimators.\n",
    "   - **Interpreting Values:**  \n",
    "     - **High Value (closer to 0.3):** Faster learning; risk of overshooting the optimal solution, potentially leading to overfitting.\n",
    "     - **Low Value (closer to 1e-3):** Slower learning; may require more estimators to converge, but can lead to better generalization.\n",
    "\n",
    "2. **max_depth**  \n",
    "   - **What it does:** Sets the maximum depth of each decision tree. This controls the complexity of the model.\n",
    "   - **Interpreting Values:**  \n",
    "     - **High Value (closer to 10):** Allows for deeper trees, capturing more complex patterns but with a higher risk of overfitting.\n",
    "     - **Low Value (closer to 3):** Results in shallower trees, which may underfit if the data is complex, but generally increases model generalizability.\n",
    "\n",
    "3. **n_estimators**  \n",
    "   - **What it does:** Specifies the number of boosting rounds (i.e., trees) to build.\n",
    "   - **Interpreting Values:**  \n",
    "     - **High Value:** More trees can lead to better performance on training data, but might also cause overfitting if not regulated by other parameters.\n",
    "     - **Low Value:** Fewer trees can lead to faster training and less overfitting, but might not capture enough complexity in the data.\n",
    "\n",
    "4. **subsample**  \n",
    "   - **What it does:** Represents the fraction of samples used for fitting each individual tree.\n",
    "   - **Interpreting Values:**  \n",
    "     - **High Value (closer to 1.0):** Uses most of the data for each tree, which can increase accuracy but may also increase overfitting.\n",
    "     - **Low Value (closer to 0.5):** Uses fewer samples per tree, introducing randomness that can reduce overfitting but might also lead to underfitting if too low.\n",
    "\n",
    "5. **colsample_bytree**  \n",
    "   - **What it does:** Specifies the fraction of features (columns) used when building each tree.\n",
    "   - **Interpreting Values:**  \n",
    "     - **High Value (closer to 1.0):** More features are used, which can increase accuracy but also the risk of overfitting.\n",
    "     - **Low Value (closer to 0.5):** Fewer features are used per tree, adding regularization and potentially improving generalizability.\n",
    "\n",
    "6. **gamma**  \n",
    "   - **What it does:** Sets the minimum loss reduction required to make a further partition on a leaf node. It acts as a regularization parameter.\n",
    "   - **Interpreting Values:**  \n",
    "     - **High Value:** Demands a larger reduction in loss to split a node, leading to simpler trees (more regularization). This can prevent overfitting.\n",
    "     - **Low Value:** Allows more splits even if the loss reduction is small, potentially capturing more complex patterns but increasing the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptoa_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
